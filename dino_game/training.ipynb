{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\programdata\\anaconda3\\envs\\rl_learning\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(128, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "c:\\programdata\\anaconda3\\envs\\rl_learning\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "c:\\programdata\\anaconda3\\envs\\rl_learning\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"linear\", kernel_initializer=\"uniform\")`\n",
      "c:\\programdata\\anaconda3\\envs\\rl_learning\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:1031: UserWarning: name used for saved screenshot does not match file type. It should end with a `.png` extension\n",
      "  \"type. It should end with a `.png` extension\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.00941304]\n",
      " [0.0129923 ]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 352, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.01323002]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 44, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 48, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.02399161]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 48, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[0.0129923]\n",
      " [0.0129923]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.02349961]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.01904214]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 18, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.02037566]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 54, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 46, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.02438875]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.02707356]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[0.0129923]\n",
      " [0.0129923]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.02273561]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.0205859]\n",
      " [0.0129923]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 22, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 352, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.02382232]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.02523163]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.0192537]\n",
      " [0.0129923]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.02040179]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 22, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.02373844]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.0213655]\n",
      " [0.0129923]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[0.0129923]\n",
      " [0.0129923]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.01917109]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 4, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 16, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 15, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.01788808]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.02106846]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 27, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.01518917]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 352, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 46, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[0.0129923]\n",
      " [0.0129923]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.01873126]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 135, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.01702064]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 18, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.01778101]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.02188403]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 8, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.02268145]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 135, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.01777388]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 18, done: False\n",
      "Observing Finished Run New Episode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.02037815]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 54, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 359, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.03783924]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[0.0129923]\n",
      " [0.0129923]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.02052002]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.02379034]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.01892499]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.02076143]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.0203025]\n",
      " [0.0129923]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 54, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 359, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.02710146]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.02267983]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 135, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.01975387]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 18, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.02073965]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.01531455]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 359, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[0.0129923]\n",
      " [0.0129923]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.0218939]\n",
      " [0.0129923]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.02246405]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 135, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.01750144]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 18, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.02054232]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 46, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.01240914]\n",
      " [0.0129923 ]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.01943789]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[0.02162908]\n",
      " [0.0129923 ]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 135, done: False\n",
      "Observing Finished Run New Episode\n",
      "could not broadcast input array from shape (2,60,232,3) into shape (1,60,232,3)\n",
      "Learning Finished\n",
      "[[[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.74403]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 22, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.68797]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 27, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.7379 ]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.25658]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[158.35188]\n",
      " [162.16652]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.65556]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.76076]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.68729]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.50711]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[161.62743]\n",
      " [162.16652]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 44, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[161.0097 ]\n",
      " [162.16652]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 50, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[161.20177]\n",
      " [162.16652]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 53, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[158.49548]\n",
      " [162.16652]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: 1, observation shape: (60, 232, 3), reward: 53, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[162.16652]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 135, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.64993]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 18, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.6461 ]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.0303 ]\n",
      " [162.16652]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 54, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[161.50233]\n",
      " [162.16652]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 46, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[160.83119]\n",
      " [162.16652]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.6987 ]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.68619]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 54, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 46, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[162.16652]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.6833 ]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 22, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.69695]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 27, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.72826]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 352, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.1319 ]\n",
      " [162.16652]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[160.83815]\n",
      " [162.16652]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 44, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 49, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[161.3793 ]\n",
      " [162.16652]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 52, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 52, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[162.16652]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.66093]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.33768]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 41, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[161.85075]\n",
      " [162.16652]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[158.73595]\n",
      " [162.16652]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[162.16652]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 135, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 18, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.69098]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.68782]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 54, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 46, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[161.34041]\n",
      " [162.16652]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.74194]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 18, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.36522]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 54, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.32787]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 46, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[161.63574]\n",
      " [162.16652]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[162.16652]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.68317]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 18, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.61655]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.30482]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[161.82884]\n",
      " [162.16652]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: 1, observation shape: (60, 232, 3), reward: 44, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[160.95287]\n",
      " [162.16652]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 49, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[161.11458]\n",
      " [162.16652]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 53, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[158.56808]\n",
      " [162.16652]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 53, done: True\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.6921 ]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[162.68211]\n",
      " [162.16652]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 18, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "could not broadcast input array from shape (2,60,232,3) into shape (1,60,232,3)\n",
      "Learning Finished\n",
      "[[[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 93, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.54996]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 14, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.63947]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 19, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.54308]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.59645]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[195.70786]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 54, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[195.78021]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 359, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[195.39957]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 22, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.59505]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 27, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 352, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.06009]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[195.71677]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[190.11166]\n",
      " [194.90323]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.65213]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.55688]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.50842]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 359, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[194.60199]\n",
      " [194.90323]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 44, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 50, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[195.2048 ]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 52, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[189.6818 ]\n",
      " [194.90323]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 52, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[194.90323]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.44519]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.53091]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 18, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.51596]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.55185]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.4622 ]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.45029]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.50507]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 18, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.49847]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.49557]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 54, done: False\n",
      "Observing Finished Run New Episode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: 0, observation shape: (60, 232, 3), reward: 359, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[194.26233]\n",
      " [194.90323]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 44, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[193.06369]\n",
      " [194.90323]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 50, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[193.89685]\n",
      " [194.90323]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 53, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 53, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[194.90323]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 8, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 14, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.5668 ]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 20, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 26, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 352, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[190.06746]\n",
      " [194.90323]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.63892]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.66794]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 22, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.61057]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[195.2836 ]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[194.90323]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.61945]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 135, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 19, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[195.69345]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[195.84274]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 41, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[190.31851]\n",
      " [194.90323]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.441  ]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 135, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.52264]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 18, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.49329]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.51085]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 359, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.49615]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.57715]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[196.56085]\n",
      " [194.90323]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "could not broadcast input array from shape (2,60,232,3) into shape (1,60,232,3)\n",
      "Learning Finished\n",
      "[[[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 8, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.79277]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: 0, observation shape: (60, 232, 3), reward: 1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.51083]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 8, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 135, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 18, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.45015]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.45325]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 359, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[215.41089]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[207.75471]\n",
      " [213.47005]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[213.47005]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.38467]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.57759]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 135, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.46585]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 18, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.43799]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.42818]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.47531]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 359, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[214.46501]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[208.35982]\n",
      " [213.47005]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.52118]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.50613]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 22, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 27, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 352, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[208.86954]\n",
      " [213.47005]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[213.47005]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.31723]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.5325 ]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.5889 ]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 22, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.4391 ]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 27, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.48572]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 352, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[215.72229]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 387, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[207.50763]\n",
      " [213.47005]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[213.47005]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.41476]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.49771]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.62454]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 22, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.55064]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.57253]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[215.00214]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[213.47005]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.53198]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.5676 ]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 22, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.46886]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[213.47005]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.53784]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.46661]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 22, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.51984]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 27, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.45996]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 352, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[215.0982 ]\n",
      " [213.47005]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[213.47005]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.32233]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 18, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.41388]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[215.7933 ]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 54, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[215.7009 ]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 359, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[215.18382]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.35852]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.60225]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.52887]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 22, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.53888]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 27, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.61122]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[216.75261]\n",
      " [213.47005]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[208.17056]\n",
      " [213.47005]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "could not broadcast input array from shape (2,60,232,3) into shape (1,60,232,3)\n",
      "Learning Finished\n",
      "[[[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]]\n",
      "[[287.60983]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.88876]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 22, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 27, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.88998]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 352, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 387, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[292.75616]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[287.60983]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.6499 ]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.8583 ]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 22, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.77628]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[294.03464]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[281.91815]\n",
      " [287.60983]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[287.60983]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.54114]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.64188]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 18, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.6236 ]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[292.16333]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[282.05313]\n",
      " [287.60983]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.64597]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.54745]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[294.4957 ]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 359, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[291.5687 ]\n",
      " [287.60983]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.72342]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.75992]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.7733 ]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.7833 ]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[292.06625]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[281.58145]\n",
      " [287.60983]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[287.60983]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.59406]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 18, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.68942]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.66757]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.66324]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 54, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 359, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.54688]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.79422]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 22, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 27, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.7396 ]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 352, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[292.70444]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 387, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[291.2772 ]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[280.23148]\n",
      " [287.60983]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.62735]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.81168]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 22, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 27, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 352, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[287.60983]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.8582 ]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.77634]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.8326 ]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.80374]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 359, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[290.98944]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[280.1453 ]\n",
      " [287.60983]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.68375]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[293.6358 ]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 18, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 54, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 359, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[279.3456 ]\n",
      " [287.60983]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[287.60983]\n",
      " [287.60983]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "could not broadcast input array from shape (2,60,232,3) into shape (1,60,232,3)\n",
      "Learning Finished\n",
      "[[[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   ...\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]]\n",
      "[[375.87155]\n",
      " [375.87155]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[384.8826 ]\n",
      " [375.87155]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 18, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[384.88455]\n",
      " [375.87155]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[384.86594]\n",
      " [375.87155]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 359, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[375.87155]\n",
      " [375.87155]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[384.92917]\n",
      " [375.87155]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[385.0455 ]\n",
      " [375.87155]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 25, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 358, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[382.58463]\n",
      " [375.87155]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[363.62692]\n",
      " [375.87155]]\n",
      "action: 1, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "[[375.87155]\n",
      " [375.87155]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[384.91525]\n",
      " [375.87155]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 22, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 27, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[385.03543]\n",
      " [375.87155]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 352, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 387, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 45, done: True\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: -1, done: False\n",
      "Observing Finished Run New Episode\n",
      "action: 0, observation shape: (60, 232, 3), reward: 7, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[385.02774]\n",
      " [375.87155]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 12, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[384.82236]\n",
      " [375.87155]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 17, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[384.97937]\n",
      " [375.87155]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 22, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[384.9631 ]\n",
      " [375.87155]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 28, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[384.87296]\n",
      " [375.87155]]\n",
      "action: 0, observation shape: (60, 232, 3), reward: 35, done: False\n",
      "Observing Finished Run New Episode\n",
      "[[386.17227]\n",
      " [375.87155]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-12d28d926a60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;31m# See state of the game, reward... after performing the action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mobservation_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'action: {}, observation shape: {}, reward: {}, done: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobservation_new\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mobs_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (Formatting issues)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Code\\rl_learning\\controler.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action, epsilon)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture_screen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mController\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_reward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Code\\rl_learning\\controler.py\u001b[0m in \u001b[0;36mget_reward\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     56\u001b[0m         process = subprocess.Popen([r'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe', '1.png', '1'],\n\u001b[0;32m     57\u001b[0m                                    stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'1.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\rl_learning\\lib\\subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m    848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stdin_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 850\u001b[1;33m                 \u001b[0mstdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    851\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# INITIALIZATION: libraries, parameters, network...\n",
    "\n",
    "from keras.models import Sequential      # One layer after the other\n",
    "from keras.layers import Dense, Flatten, Conv2D  # Dense layers are fully connected layers, Flatten layers flatten out multidimensional inputs\n",
    "from collections import deque            # For storing moves\n",
    "from controler import Controller\n",
    "import numpy as np\n",
    "import gym                                # To train our network\n",
    "env = Controller()          # Choose game (any in the gym should work)\n",
    "\n",
    "import random     # For sampling batches from the observations\n",
    "\n",
    "\n",
    "# Create network. Input is two consecutive game states, output is Q-values of the possible moves.\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(60, 232, 3)))\n",
    "# model.add(Dense(20, input_shape=(2,) + env.observation_space.shape, init='uniform', activation='relu'))\n",
    "model.add(Flatten())       # Flatten input so as to have no problems with processing\n",
    "model.add(Dense(128, init='uniform', activation='relu'))\n",
    "model.add(Dense(10, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='linear'))    # Same number of outputs as possible actions\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# FIRST STEP: Knowing what each action does (Observing)\n",
    "\n",
    "observetime = 100                         # Number of timesteps we will be acting on the game and observing results\n",
    "epsilon = 0.5                             # Probability of doing a random move\n",
    "gamma = 0.9                                # Discounted future reward. How much we care about steps further in time\n",
    "mb_size = 32                               # Learning minibatch size\n",
    "num_episode = 10000\n",
    "\n",
    "for episode in range(num_episode):\n",
    "    env.reset()                     # Game begins\n",
    "    observation, reward, done, _ = env.step(1, epsilon)\n",
    "    # (Formatting issues) Making the observation the first element of a batch of inputs\n",
    "    # obs = np.expand_dims(observation, axis=0)\n",
    "    state = np.stack((observation, observation), axis=0)\n",
    "    print(state)\n",
    "    \n",
    "    # Parameters\n",
    "    D = deque()                                # Register where the actions will be stored\n",
    "\n",
    "    for t in range(observetime):\n",
    "        if np.random.rand() <= epsilon:\n",
    "            action = np.random.randint(0, 1, size=1)[0]  # jump or not\n",
    "        else:\n",
    "            Q = model.predict(state)          # Q-values predictions\n",
    "            print(Q)\n",
    "            action = np.argmax(Q)             # Move with highest Q-value is the chosen one\n",
    "\n",
    "        # See state of the game, reward... after performing the action\n",
    "        observation_new, reward, done, info = env.step(action, epsilon)\n",
    "        print('action: {}, observation shape: {}, reward: {}, done: {}'.format(action, observation_new.shape, reward, done))\n",
    "        obs_new = np.expand_dims(observation_new, axis=0)  # (Formatting issues)\n",
    "\n",
    "        # Update the input with the new state of the game\n",
    "        state_new = np.append(obs_new, state[1:, :, :, :], axis=0)\n",
    "        D.append((state, action, reward, state_new, done))         # 'Remember' action and consequence\n",
    "        state = state_new         # Update state\n",
    "        if done:\n",
    "            env.reset()           # Restart game if it's finished\n",
    "\n",
    "            # (Formatting issues) Making the observation the first element of a batch of inputs\n",
    "            obs = np.expand_dims(observation, axis=0)\n",
    "            state = np.stack((observation, observation), axis=0)\n",
    "        print('Observing Finished Run New Episode')\n",
    "\n",
    "    minibatch = random.sample(D, mb_size)  # Sample some moves\n",
    "\n",
    "    inputs_shape = (mb_size,) + state.shape[1:]\n",
    "    inputs = np.zeros(inputs_shape)\n",
    "    targets = np.zeros((mb_size, 1))\n",
    "\n",
    "    for i in range(0, mb_size):\n",
    "        state = minibatch[i][0]\n",
    "        action = minibatch[i][1]\n",
    "        reward = minibatch[i][2]\n",
    "        state_new = minibatch[i][3]\n",
    "        done = minibatch[i][4]\n",
    "\n",
    "        # Build Bellman equation for the Q function\n",
    "        try:\n",
    "            inputs[i:i+2] = np.expand_dims(state, axis=0)\n",
    "            predict = model.predict(state)\n",
    "            targets[i] = predict[0]\n",
    "            targets[i+1] = predict[1]\n",
    "            Q_sa = model.predict(state_new)\n",
    "\n",
    "            if done:\n",
    "                targets[i, action] = reward\n",
    "            else:\n",
    "                targets[i, action] = reward + gamma * np.max(Q_sa)\n",
    "\n",
    "            # Train network to output the Q function\n",
    "            model.train_on_batch(inputs, targets)\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "    print('Learning Finished')\n",
    "    model.save('saved_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# SECOND STEP: Learning from the observations (Experience replay)\n",
    "\n",
    "def retrain_model(model_training):\n",
    "    \n",
    "    return model_training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIRD STEP: Play!\n",
    "\n",
    "env.reset()\n",
    "observation, reward, done, _ = env.step(1, epsilon)\n",
    "state = np.stack((observation, observation), axis=0)\n",
    "done = False\n",
    "tot_reward = 0.0\n",
    "while not done:\n",
    "    Q = model.predict(state)\n",
    "    action = np.argmax(Q)\n",
    "    observation, reward, done, info = env.step(action, epsilon)\n",
    "    obs = np.expand_dims(observation, axis=0)\n",
    "    state = np.stack((observation, observation), axis=0)\n",
    "    tot_reward += reward\n",
    "print('Game ended! Total reward: {}'.format(reward))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
